{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Steps\n",
    "\n",
    "#### Steps we’ve covered so far:\n",
    "\n",
    "1. Camera calibration\n",
    "2. Distortion correction\n",
    "3. Color/gradient threshold\n",
    "4. Perspective transform\n",
    "\n",
    "#### After doing these steps, you’ll be given two additional steps for the project:\n",
    "\n",
    "5. Detect lane lines\n",
    "6. Determine the lane curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Processing Each Image\n",
    "![](./img/color-shadow-example.jpg)\n",
    "\n",
    "In the project at the end of this module, the first thing you'll do is to compute the camera calibration matrix and distortion coefficients. You `only need to compute these once, and then you'll apply them to undistort each new frame`. Next, you'll apply thresholds to create a binary image and then apply a perspective transform.\n",
    "\n",
    "#### Thresholding\n",
    "You'll want to try out various combinations of color and gradient thresholds to generate a binary image where the lane lines are clearly visible. There's more than one way to achieve a good result, but for example, given the image above, the output you're going for should look something like this:\n",
    "\n",
    "![](./img/binary-combo-img.jpg)\n",
    "\n",
    "#### Perspective Transform\n",
    "Next, you want to identify `four source points` for your perspective transform. In this case, you can assume the road is a flat plane. This isn't strictly true, but it can serve as an approximation for this project. You would like to pick four points in a trapezoidal shape (similar to region masking) that would represent a rectangle when looking down on the road from above.\n",
    "\n",
    "The easiest way to do this is to investigate an image where the lane lines are straight, and find four points lying along the lines that, after perspective transform, make the lines look straight and vertical from a bird's eye view perspective.\n",
    "\n",
    "#### Here's an example of the result you are going for with straight lane lines:\n",
    "![](./img/warped-straight-lines.jpg)\n",
    "\n",
    "#### Now for curved lines\n",
    "Those same four source points will now work to transform any image (again, under the assumption that the road is flat and the camera perspective hasn't changed). When applying the transform to new images, the test of whether or not you got the transform correct, is that the lane lines should appear parallel in the warped images, whether they are straight or curved.\n",
    "\n",
    "Here's an example of applying a perspective transform to your thresholded binary image, using the same source and destination points as above, showing that the curved lines are (more or less) parallel in the transformed image:\n",
    "![](./img/warped-curved-lines.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Finding the Lines: Histogram Peaks\n",
    "\n",
    "#### Locate the Lane Lines\n",
    "![SDC](./img/warped-example.jpg)\n",
    "\n",
    "You now have a thresholded warped image and you're ready to map out the lane lines! There are many ways you could go about this, but here's one example of how you might do it:\n",
    "\n",
    "#### Line Finding Method: Peaks in a Histogram\n",
    "\n",
    "After applying calibration, thresholding, and a perspective transform to a road image, you should have a binary image where the lane lines stand out clearly. However, you still need to decide explicitly which pixels are part of the lines and which belong to the left line and which belong to the right line.\n",
    "\n",
    "Plotting a histogram of where the binary activations occur across the image is one potential solution for this. In the quiz below, let's take a couple quick steps to create our histogram!\n",
    "\n",
    "#### axis = 0表示对最外层[]里的最大单位块做块与块之间的运算,同时移除最外层[]\n",
    "#### axis= 1表示对第二外层[]里的最大单位块做块与块之间的运算,同时移除第二外层[]\n",
    "histogram = np.sum(bottom_half, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x163f47cf6d8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load our image\n",
    "# `mpimg.imread` will load .jpg as 0-255, so normalize back to 0-1\n",
    "img = mpimg.imread('warped_example.jpg')/255\n",
    "\n",
    "def hist(img):\n",
    "    # TO-DO: Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "#     bottom_half = img[img.shape[0]//2:]\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "#     print(bottom_half.shape)\n",
    "#     print(type(img))\n",
    "    # TO-DO: Sum across image pixels vertically - make sure to set `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "# Create histogram of image binary activations\n",
    "histogram = hist(img)\n",
    "\n",
    "# Visualize the resulting histogram\n",
    "plt.plot(histogram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliding Window\n",
    "With this histogram we are adding up the pixel values along each column in the image. In our thresholded binary image, pixels are either 0 or 1, so the two most prominent peaks in this histogram will be good indicators of the x-position of the base of the lane lines. We can use that as a starting point for where to search for the lines. From that point, we can use a sliding window, placed around the line centers, to find and follow the lines up to the top of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./video/sliding_window.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"./video/sliding_window.mp4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Finding the Lines: Sliding Window\n",
    "\n",
    "#### Implement Sliding Windows and Fit a Polynomial(adj.多项式的;多词学名的n.多项式;多词学名)\n",
    "![](./img/sliding_windows_and_fit_a_polynomial.png)\n",
    "\n",
    "As shown in the previous animation, we can use the two highest peaks from our histogram as a starting point for determining where the lane lines are, and then use sliding windows moving upward in the image (further along the road) to determine where the lane lines go.\n",
    "\n",
    "#### Split the histogram for the two lines\n",
    "The first step we'll take is to split the histogram into two sides, one for each lane line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have created a warped binary image called \"binary_warped\"\n",
    "# Take a histogram of the bottom half of the image\n",
    "histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "# Create an output image to draw on and visualize the result\n",
    "out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "# These will be the starting point for the left and right lines\n",
    "midpoint = np.int(histogram.shape[0]//2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above, we also create out_img to help with visualizing our output later on.\n",
    "\n",
    "#### Set up windows and window hyperparameters\n",
    "Our next step is to set a few hyperparameters related to our sliding windows, and set them up to iterate across the binary activations in the image. We have some base hyperparameters below, but don't forget to try out different values in your own implementation to see what works best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "\n",
    "# Set height of windows - based on nwindows above and image shape\n",
    "window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "# Identify the x and y positions of all nonzero (i.e. activated) pixels in the image\n",
    "nonzero = binary_warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "# Current positions to be updated later for each window in nwindows\n",
    "leftx_current = leftx_base\n",
    "rightx_current = rightx_base\n",
    "\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds = []\n",
    "right_lane_inds = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterate through `nwindows` to track curvature**\n",
    "Now that we've set up what the windows look like and have a starting point, we'll want to loop for `nwindows`, with the given window sliding left or right if it finds the mean position of activated pixels within the window to have shifted.\n",
    "\n",
    "You'll implement this part in the quiz below, but here's a few steps to get you started:\n",
    "\n",
    "1. Loop through each window in nwindows\n",
    "2. Find the boundaries of our current window. This is based on a combination of the current window's starting point (leftx_current and rightx_current), as well as the margin you set in the hyperparameters.\n",
    "3. Use `cv2.rectangle` to draw these window boundaries onto our visualization image out_img. This is required for the quiz, but you can skip this step in practice if you don't need to visualize where the windows are.\n",
    "4. Now that we know the boundaries of our window, find out which activated pixels from nonzeroy and nonzerox above actually fall into the window.\n",
    "5. Append these to our lists left_lane_inds and right_lane_inds.\n",
    "6. If the number of pixels you found in Step 4 are greater than your hyperparameter `minpix`, re-center our window (i.e. `leftx_current` or `rightx_current`) based on the mean position of these pixels.\n",
    "\n",
    "#### Fit a polynomial\n",
    "Now that we have found all our pixels belonging to each line through the sliding window method, it's time to fit a polynomial to the line. First, we have a couple small steps to ready our pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "left_lane_inds = np.concatenate(left_lane_inds)\n",
    "right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll let you implement the function for the polynomial in the quiz below using `np.polyfit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we have `left_fit` and `right_fit` from `np.polyfit` before\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of how we fit the lines above - while normally you calculate a y-value for a given x, here we do the opposite. Why? Because we expect our lane lines to be (mostly) vertically-oriented.\n",
    "\n",
    "#### Visualization\n",
    "Once you reach this point, you're done! But here is how you can visualize the result as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img[lefty, leftx] = [255, 0, 0]\n",
    "out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "In the below quiz, implement the following (see TO-DO's):\n",
    "\n",
    "* Steps 2, 4 and 6 from above within the `for` loop in `find_lane_pixels()` - find the window boundaries, find all pixels within those boundaries, and if there are more than `minpix`, slide the window over to the mean of these pixels.\n",
    "* Fit a polynomial to all the relevant pixels you've found in your sliding windows in `fit_polynomial()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load our image\n",
    "binary_warped = mpimg.imread('warped_example.jpg')\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = 0  # Update this\n",
    "        win_xleft_high = 0  # Update this\n",
    "        win_xright_low = 0  # Update this\n",
    "        win_xright_high = 0  # Update this\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = None\n",
    "        good_right_inds = None\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        pass # Remove this when you add your function\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = None\n",
    "    right_fit = None\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img\n",
    "\n",
    "\n",
    "out_img = fit_polynomial(binary_warped)\n",
    "\n",
    "plt.imshow(out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Finding the Lines: Search from Prior\n",
    "\n",
    "#### Skip the sliding windows step once you've found the lines\n",
    "![](./img/search_from_prior.png)\n",
    "Great work! You've now built an algorithm that uses sliding windows to track the lane lines out into the distance. However, using the full algorithm from before and starting fresh on every frame may seem inefficient, as the lane lines don't necessarily move a lot from frame to frame.\n",
    "\n",
    "In the next frame of video you don't need to do a blind search again, but instead you can just search in a margin around the previous lane line position, like in the above image. The green shaded area shows where we searched for the lines this time. So, once you know where the lines are in one frame of video, you can do a highly targeted search for them in the next frame.\n",
    "\n",
    "This is equivalent to using a customized region of interest for each frame of video, and should help you track the lanes through sharp curves and tricky conditions. If you lose track of the lines, go back to your sliding windows search or other method to rediscover them.\n",
    "\n",
    "Let's walk through one way to do this, and then you'll build it out further in a quiz below.\n",
    "\n",
    "#### Use the previous polynomial to skip the sliding window\n",
    "In the previous quiz, we used `left_lane_inds` and `right_lane_indsto` hold the pixel values contained within the boundaries of a given sliding window. This time, we'll take the polynomial functions we fit before (`left_fit` and `right_fit`), along with a hyperparameter `margin`, to determine which activated pixels fall into the green shaded areas from the above image. Note that this `margin` can be a different value than the one originally used for your sliding windows!\n",
    "\n",
    "To implement this in the below quiz, you'll want to grab only those pixels with x-values that are +/- your `margin` from your polynomial lines. Note that you'll only need to implement `left_lane_inds` and `right_lane_inds` in the quiz - most of the surrounding code, ignoring iterating through the windows, is the same as before!\n",
    "\n",
    "The way we'll visualize this is a bit different than last time around, however, so make sure to pay attention to that if you want to visualize this step while working on your project.\n",
    "\n",
    "Quiz\n",
    "In the below quiz, implement the following (see TO-DO's):\n",
    "\n",
    "* Fit a polynomial to all the relevant pixels you've found in your sliding windows in `fit_poly()`.\n",
    "* Set the area to search for activated pixels based on `margin` out from your fit polynomial within `search_around_poly`. Note that the quiz grader expects a `margin` of `100` pixels, but you can tune this as part of your own project!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load our image - this should be a new frame since last time!\n",
    "binary_warped = mpimg.imread('warped_example.jpg')\n",
    "\n",
    "# Polynomial fit values from the previous frame\n",
    "# Make sure to grab the actual values from the previous step in your project!\n",
    "left_fit = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])\n",
    "right_fit = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = None\n",
    "    right_fit = None\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = None\n",
    "    right_fitx = None\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def search_around_poly(binary_warped):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = None\n",
    "    right_lane_inds = None\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run image through the pipeline\n",
    "# Note that in your project, you'll also want to feed in the previous fits\n",
    "result = search_around_poly(binary_warped)\n",
    "\n",
    "# View your output\n",
    "plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting on Large Curves\n",
    "One thing to consider in our current implementation of sliding window search is what happens when we arrive at the left or right edge of an image, such as when there is a large curve on the road ahead. If `minpix` is not achieved (i.e. the curve ran off the image), the starting position of our next window doesn't change, so it is just positioned directly above the previous window. This will repeat for however many windows are left in `nwindows`, stacking the sliding windows vertically against the side of the image, and likely leading to an imperfect polynomial fit.\n",
    "\n",
    "Can you think of a way to solve this issue? If you want to tackle the curves on the harder challenge video as part of the project, you might want to include this in your lane finding algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Measuring Curvature I\n",
    "You're getting very close to a final result! You have a thresholded image, where you've estimated which pixels belong to the left and right lane lines (shown in red and blue, respectively, below), and you've fit a polynomial to those pixel positions. Next we'll compute the radius of curvature of the fit.\n",
    "![](./img/color-fit-lines.jpg)\n",
    "In the last exercise, you located the lane line pixels, used their x and y pixel positions to fit a second order polynomial curve:\n",
    "\n",
    "${f(y) = Ay^2 + By + C}$\n",
    "\n",
    "You're fitting for${f(y)}$, rather than ${f(x)}$, because the lane lines in the warped image are near vertical and may have the same xx value for more than one ${y}$ value.\n",
    "\n",
    "Radius of Curvature\n",
    "The radius of curvature (awesome tutorial here) at any point xx of the function ${x=f(y)}$ is given as follows:\n",
    "\n",
    "${\\LARGE R_{curve} = \\frac{[1 + (\\frac{dx}{dy})^2]^{3/2}}{|\\frac{d^2x}{dy^2}|}}$\n",
    "\n",
    "In the case of the second order polynomial above, the first and second derivatives are:\n",
    "\n",
    "${\\large f'(y) = \\frac{dx}{dy} = 2Ay + B}$\n",
    "\n",
    "${\\large f''(y) = \\frac{d^2x}{dy^2} = 2A}$\n",
    "\n",
    "So, our equation for radius of curvature becomes:\n",
    "\n",
    "${\\LARGE R_{curve} = \\frac{(1 + (2Ay + B)^2)^{3/2}}{\\left |2A \\right |}}$\n",
    "\n",
    "The yy values of your image increase from top to bottom, so if, for example, you wanted to measure the radius of curvature closest to your vehicle, you could evaluate the formula above at the yy value corresponding to the bottom of your image, or in Python, at `yvalue = image.shape[0]`.\n",
    "\n",
    "#### Implementing the Calculation\n",
    "#### Generate some fake data first\n",
    "Most of the code below is just to generate some fake data to visualize with - everything up until the actual plotting of the data below should be replaced with your algorithms from before in your own implementation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Generate some fake data to represent lane-line pixels\n",
    "ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "quadratic_coeff = 3e-4 # arbitrary quadratic coefficient\n",
    "# For each y position generate random x position within +/-50 pix\n",
    "# of the line base position in each case (x=200 for left, and x=900 for right)\n",
    "leftx = np.array([200 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                              for y in ploty])\n",
    "rightx = np.array([900 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                for y in ploty])\n",
    "\n",
    "leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "\n",
    "# Fit a second order polynomial to pixel positions in each fake lane line\n",
    "left_fit = np.polyfit(ploty, leftx, 2)\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fit = np.polyfit(ploty, rightx, 2)\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# Plot up the fake data\n",
    "mark_size = 3\n",
    "plt.plot(leftx, ploty, 'o', color='red', markersize=mark_size)\n",
    "plt.plot(rightx, ploty, 'o', color='blue', markersize=mark_size)\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(0, 720)\n",
    "plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "plt.gca().invert_yaxis() # to visualize as we do the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks like this:\n",
    "![](./img/measure_curvature_01.png)\n",
    "Implementing the calculation itself\n",
    "Now we have polynomial fits and we can calculate the radius of curvature.\n",
    "\n",
    "In the below quiz, you'll implement the radius of curvature calculation (using our fake generated data from above - remember that you'll be using your own implemented algorithm in place of the `generate_data` function in the below quiz!).\n",
    "\n",
    "Use the ${\\large R_{curve}}$ equation above in order to calculate `left_curverad` and `right_curverad` in the `measure_curvature_pixels()` function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curve_pixels.py\n",
    "import numpy as np\n",
    "\n",
    "def generate_data():\n",
    "    '''\n",
    "    Generates fake data to use for calculating lane curvature.\n",
    "    In your own project, you'll ignore this function and instead\n",
    "    feed in the output of your lane detection algorithm to\n",
    "    the lane curvature calculation.\n",
    "    '''\n",
    "    # Set random seed number so results are consistent for grader\n",
    "    # Comment this out if you'd like to see results on different random data!\n",
    "    np.random.seed(0)\n",
    "    # Generate some fake data to represent lane-line pixels\n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    quadratic_coeff = 3e-4 # arbitrary quadratic coefficient\n",
    "    # For each y position generate random x position within +/-50 pix\n",
    "    # of the line base position in each case (x=200 for left, and x=900 for right)\n",
    "    leftx = np.array([200 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                    for y in ploty])\n",
    "    rightx = np.array([900 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                    for y in ploty])\n",
    "\n",
    "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "\n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    left_fit = np.polyfit(ploty, leftx, 2)\n",
    "    right_fit = np.polyfit(ploty, rightx, 2)\n",
    "    \n",
    "    return ploty, left_fit, right_fit\n",
    "\n",
    "    \n",
    "def measure_curvature_pixels():\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''\n",
    "    # Start by generating our fake example data\n",
    "    # Make sure to feed in your real data instead in your project!\n",
    "    ploty, left_fit, right_fit = generate_data()\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = 0  ## Implement the calculation of the left line here\n",
    "    right_curverad = 0  ## Implement the calculation of the right line here\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "\n",
    "# Calculate the radius of curvature in pixels for both lane lines\n",
    "left_curverad, right_curverad = measure_curvature_pixels()\n",
    "\n",
    "print(left_curverad, right_curverad)\n",
    "# Should see values of 1625.06 and 1976.30 here, if using\n",
    "# the default `generate_data` function with given seed number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Measuring Curvature II\n",
    "#### From Pixels to Real-World\n",
    "Great! You've now calculated the radius of curvature for our lane lines. But now we need to stop and think... We've calculated the radius of curvature based on pixel values, so the radius we are reporting is in pixel space, which is not the same as real world space. So we actually need to repeat this calculation after converting our x and y values to real world space.\n",
    "\n",
    "This involves measuring how long and wide the section of lane is that we're projecting in our warped image. We could do this in detail by measuring out the physical lane in the field of view of the camera, but for this project, you can assume that if you're projecting a section of lane similar to the images above, the lane is about 30 meters long and 3.7 meters wide. Or, if you prefer to derive a conversion from pixel space to world space in your own images, compare your images with U.S. regulations that require a minimum lane width of 12 feet or 3.7 meters, and the dashed lane lines are 10 feet or 3 meters long each.\n",
    "\n",
    "Let's say that our camera image has 720 relevant pixels in the y-dimension (remember, our image is perspective-transformed!), and we'll say roughly 700 relevant pixels in the x-dimension (our example of fake generated data above used from 200 pixels on the left to 900 on the right, or 700). Therefore, to convert from pixels to real-world meter measurements, we can use:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below quiz, you'll use the above conversions in order to adjust your calculation from before to give real-world lane curvature values. Once again, you'll focus on the `left_curverad` and `right_curverad` values within the new `measure_curvature_real()` function; however, you'll also need to adjust how you use `np.polyfit()` within `generate_data()` in order for this to work correctly. How do you need to change these to convert to meters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_data(ym_per_pix, xm_per_pix):\n",
    "    '''\n",
    "    Generates fake data to use for calculating lane curvature.\n",
    "    In your own project, you'll ignore this function and instead\n",
    "    feed in the output of your lane detection algorithm to\n",
    "    the lane curvature calculation.\n",
    "    '''\n",
    "    # Set random seed number so results are consistent for grader\n",
    "    # Comment this out if you'd like to see results on different random data!\n",
    "    np.random.seed(0)\n",
    "    # Generate some fake data to represent lane-line pixels\n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    quadratic_coeff = 3e-4 # arbitrary quadratic coefficient\n",
    "    # For each y position generate random x position within +/-50 pix\n",
    "    # of the line base position in each case (x=200 for left, and x=900 for right)\n",
    "    leftx = np.array([200 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                    for y in ploty])\n",
    "    rightx = np.array([900 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                    for y in ploty])\n",
    "\n",
    "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    ##### TO-DO: Fit new polynomials to x,y in world space #####\n",
    "    ##### Utilize `ym_per_pix` & `xm_per_pix` here #####\n",
    "    left_fit_cr = np.polyfit(ploty, leftx, 2)\n",
    "    right_fit_cr = np.polyfit(ploty, rightx, 2)\n",
    "    \n",
    "    return ploty, left_fit_cr, right_fit_cr\n",
    "\n",
    "    \n",
    "def measure_curvature_real():\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Start by generating our fake example data\n",
    "    # Make sure to feed in your real data instead in your project!\n",
    "    ploty, left_fit_cr, right_fit_cr = generate_data(ym_per_pix, xm_per_pix)\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = 0  ## Implement the calculation of the left line here\n",
    "    right_curverad = 0  ## Implement the calculation of the right line here\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "\n",
    "# Calculate the radius of curvature in meters for both lane lines\n",
    "left_curverad, right_curverad = measure_curvature_real()\n",
    "\n",
    "print(left_curverad, 'm', right_curverad, 'm')\n",
    "# Should see values of 533.75 and 648.16 here, if using\n",
    "# the default `generate_data` function with given seed number\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Additional Resources on Computer Vision\n",
    "\n",
    "Additional Resources on Computer Vision\n",
    "Nice work reaching the end of the computer vision content! While you still have the project left to do here, we're also providing some additional resources and recent research on the topic that you can come back to if you have time later on.\n",
    "\n",
    "Reading research papers is a great way to get exposure to the latest and greatest in the field, as well as expand your learning. However, just like the project ahead, it's often best to learn by doing - if you find a paper that really excites you, try to implement it (or even something better) yourself!\n",
    "\n",
    "#### Optional Reading\n",
    "All of these are completely optional reading - you could spend hours reading through the entirety of these! We suggest moving onto the project first so you have what you’ve learned fresh on your mind, before coming back to check these out.\n",
    "\n",
    "We've categorized these papers to hopefully help you narrow down which ones might be of interest, as well as highlighted a couple key reads by category by including their Abstract section, which summarizes the paper.\n",
    "\n",
    "***\n",
    "\n",
    "#### Lane Finding with Semantic Segmentation\n",
    "\n",
    "The below papers and resources concern a technique called semantic segmentation, where each pixel of an image gets classified individually!\n",
    "\n",
    "[Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1605.06211) by E. Shelhamer, J. Long and T. Darrell\n",
    "\n",
    ">**Abstract:** Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build \"fully convolutional\" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. [...]\n",
    "\n",
    "You can use the [KITTI road dataset](http://www.cvlibs.net/datasets/kitti/eval_road.php) with the above technique for a model that can detect open space on the road.\n",
    "\n",
    "[Lane Detection with Deep Learning (Part 1)](https://towardsdatascience.com/lane-detection-with-deep-learning-part-1-9e096f3320b7) and [(Part 2)](https://towardsdatascience.com/lane-detection-with-deep-learning-part-2-3ba559b5c5af) by M. Virgo\n",
    "\n",
    ">**Summary:** Udacity SDC student (and now Udacian!) investigates using a deep learning approach to lane detection in order to improve upon the Advanced Lane Finding project, eventually building a model with a fully convolutional neural network that detects the road is a wider variety of situations and at faster speed.\n",
    "\n",
    "***\n",
    "\n",
    "#### Other Lane Finding Techniques\n",
    "\n",
    "The below paper uses a multi-task model to identify lane and road markings, as well as vanishing point of the road, in order to build a robust model.\n",
    "\n",
    "[VPGNet: Vanishing Point Guided Network for Lane and Road Marking Detection and Recognition](https://arxiv.org/abs/1710.06288) by S. Lee, et. al.\n",
    "\n",
    ">**Abstract:** In this paper, we propose a unified end-to-end trainable multi-task network that jointly handles lane and road marking detection and recognition that is guided by a vanishing point under adverse weather conditions. We tackle rainy and low illumination conditions [...] At night, color distortion occurs under limited illumination. As a result, no benchmark dataset exists and only a few developed algorithms work under poor weather conditions. To address this shortcoming, we build up a lane and road marking benchmark which consists of about 20,000 images with 17 lane and road marking classes under four different scenarios: no rain, rain, heavy rain, and night. We train and evaluate several versions of the proposed multi-task network and validate the importance of each task. The resulting approach, VPGNet, can detect and classify lanes and road markings, and predict a vanishing point with a single forward pass. Experimental results show that our approach achieves high accuracy and robustness under various conditions in real-time (20 fps). [...]\n",
    "\n",
    "***\n",
    "\n",
    "#### Vehicle Detection\n",
    "\n",
    "The below paper builds a model to both detect vehicles as well as estimate their dimensions along the road.\n",
    "\n",
    "[Learning to Map Vehicles into Bird's Eye View](https://arxiv.org/abs/1706.08442) by A. Palazzi, et. al.\n",
    "\n",
    ">**Abstract:** Awareness of the road scene is an essential component for both autonomous vehicles and Advances Driver Assistance Systems and is gaining importance both for the academia and car companies. This paper presents a way to learn a semantic-aware transformation which maps detections from a dashboard camera view onto a broader bird's eye occupancy map of the scene. To this end, a huge synthetic dataset featuring 1M couples of frames, taken from both car dashboard and bird's eye view, has been collected and automatically annotated. A deep-network is then trained to warp detections from the first to the second view. We demonstrate the effectiveness of our model against several baselines and observe that is able to generalize on real-world data despite having been trained solely on synthetic ones.\n",
    "\n",
    "***\n",
    "You may have noticed a lot of the papers above include deep learning techniques, which are now commonly used in many computer vision applications. More on deep learning is coming up!\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
