{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Training Data\n",
    "In order to start collecting training data, you'll need to do the following:\n",
    "\n",
    "* Enter Training Mode in the simulator.\n",
    "* Start driving the car to get a feel for the controls.\n",
    "* When you are ready, hit the record button in the top right to start recording.\n",
    "* Continue driving for a few laps or till you feel like you have enough data.\n",
    "* Hit the record button in the top right again to stop recording.\n",
    "\n",
    "### Strategies for Collecting Data\n",
    "Now that you have driven the simulator and know how to record data, it's time to think about collecting data that will ensure a successful model. There are a few general concepts to think about that we will later discuss in more detail:\n",
    "\n",
    "* the car should stay in the center of the road as much as possible\n",
    "* if the car veers off to the side, it should recover back to center\n",
    "* driving counter-clockwise can help the model generalize\n",
    "* flipping the images is a quick way to augment the data\n",
    "* collecting data from the second track can also help generalize the model\n",
    "* we want to avoid overfitting or underfitting when training the model\n",
    "* knowing when to stop collecting more data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Image augmentation\n",
    "\n",
    "#### 1.1 Center and lateral images\n",
    "So, we have data from lateral cameras. But what to do with it?\n",
    "Following a suggestion from the great carND forum (by the way, almost all of these tips are from there), I added a correction angle of 0.10 to the left image, and -0.10 to the right one. The idea is to centre the car, avoid the borders.\n",
    "\n",
    "#### 1.2 Flip images\n",
    "Another excellent tip. We can randomly choose to flip the image, and invert the steering angle. This way, we can neutralize some tendency of the human driver that drove a bit more to the left or to the right of the lane.\n",
    "\n",
    "    if np.random.uniform()>0.5:\n",
    "      X_in[i,:,:,:] = cv2.flip(X_in[i,:,:,:],1)\n",
    "      Y_in[i] = -p[i] #Flipped images\n",
    "\n",
    "Be careful to use the function correctly. Flip with parameter zero will do a wrong thing.\n",
    "\n",
    "#### 1.3 Random lateral perturbation\n",
    "The idea is to move to image a randomly a bit to the left or the right, and add a proportional compensation in the angle value. In the end, I didn’t used this approach, but it is a good idea.\n",
    "\n",
    "    pix2angle = -0.05 #Opposed direction\n",
    "    latShift = random.randint(-5,5) \n",
    "    M = np.float32([[1,0,latShift],[0,1,0]])\n",
    "    imgTranslated = cv2.warpAffine(img,M,(img.shape[1],img.shape[0]))\n",
    "\n",
    "#### 1.4 Resize\n",
    "Because of computational limits, it is a good thing to resize the images, after cropping it. Using the size of NVIDIA paper (66 x 200 pixels) my laptop went out of memory. I tried (64 x 64), (64 x 96), (64 x 128)…\n",
    "I also reduced the size of the stride of the convolutional layers. Since the image is smaller, the stride can also be smaller.\n",
    "\n",
    "    X_in[i,:,:,0] = cv2.resize(imgScreenshots[i].squeeze(), (size2,size1))\n",
    "\n",
    "All of these sizes work. An curious effect. When the image is smaller, the zig zag of the car is greater. Surely because there are fewer details in the image.\n",
    "\n",
    "#### 1.5 Crop\n",
    "The image was cropped to remove irrelevant portions of the image, like the sky, or the trees. Doing this, we’re assuming the camera is fixed in a stable position.\n",
    "\n",
    "Because inside the model a image is just a matrix, a numpy command easily do this operation.\n",
    "\n",
    "    crop_img = imgRGB[40:160,10:310,:] #Throwing away to superior portion of the image and 10 pixels from each side of the original image = (160, 320)\n",
    "    \n",
    "It makes sense to do the transformations (like the lateral shift) before the cropping, since we’re losing information. Doing the opposite, we will feed the model with an image with a lateral black bar.\n",
    "\n",
    "#### 1.6 Grayscale, YUV, HSV\n",
    "I tried grayscale, full color, the Y channel of YUV, S channel of HSV…\n",
    "All of this because my model wasn’t able to avoid the dirty exit after the bridge, where there is not a clear lane mark in the road.\n",
    "Some conversion commands:\n",
    "\n",
    "    imgOut = cvtColor(img, cv2.COLOR_BGR2YUV) \n",
    "    imgOut = cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "But the real problem was that OpenCV (cv2.imread command) reads a image in BGR, and the code in drive.py, in RGB.\n",
    "I used the conversion command of opencv to transform the image in RGB.\n",
    "\n",
    "    imgOut = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "The model used full color RGB. In addition to it, I used a first layer of the NN that just transform the 3 color channels in 1 channel, with the ponderation Keras chooses, instead of me choosing the right channel.\n",
    "\n",
    "    model.add(Convolution2D(1,1,1, border_mode = ‘same’,init =’glorot_uniform’,input_shape=(size1,size2,3)))\n",
    "\n",
    "\n",
    "#### 1.7 Normalization\n",
    "Normalization is made because the neural network usually works with small numbers: sigmoid activation has range (0, 1), tanh has range (-1,1).\n",
    "Images have 3 channels (Red, Green, Blue), each channel has value 0 to 255. The normalized array has range from -1 to 1.\n",
    "\n",
    "    X_norm = X_in/127.5–1\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Neural Networks\n",
    "#### 2.1 Architecture\n",
    "Once the image processing and augmentation is done, it is time to design the Neural Network (NN) . But there are an infinite number of architectures of neural networks.\n",
    "As a starting point, I used the NVIDIA End-to-End model (https://arxiv.org/abs/1604.07316), that has the configuration described below.\n",
    "\n",
    "![](./images/cnn-architecture-624x890.png)\n",
    ">CNN architecture. The network has about 27 million connections and 250 thousand parameters.\n",
    "\n",
    "We can broadly describe the tasks of the NN in two: recognize relevant features and predict the steering angle.\n",
    "The recognition of features is carried by convolutional layer\n",
    "\n",
    "What is a convolution?\n",
    "A convolution operation is like a window that slides across the image and does a dot product. It works as a recognizer of some feature. For example, if the convolution of a triangle, the portion of the image that has that triangle will have maximum value, while some totally uncorrelated image will have minimum value.\n",
    "\n",
    "![](./images/convolution.gif)\n",
    "\n",
    "**Why so many convolutional layers?**\n",
    "Each convolutional layer is a level of abstraction above the previous layer. As an analogy, the first layer recognizes the parts of a car, the second layer recognizes the car, the third layer recognizes the scenario with the car, and so on.\n",
    "It is important to stress that we do not give the explicit features the image has to recognize. It is automatically done by the back-propagation of the neural network. It has some pros and cons. The pro is that we just feed the network. The con is that if it not work, we don’t have idea of why it didn’t work — is the network too small? Too big?\n",
    "\n",
    "**Given the features, how to decide about the steering angle?**\n",
    "It is done by **fully connected layers** after the convolutional ones.\n",
    "The matrix is flattened, because the spatial information of rows and columns doesn’t matter any longer. The NN is like a function that is feed with images, and for each image, give the steering angle as steering angle, which is compared to the angle of the human driver.\n",
    "Another thing to note is that these techniques are very new. Much of these concepts are not well understood and consolidated. It is at the same time good, because we are at the frontier of knowledge, and scary, because sometimes we simply don’t know if something works or not.\n",
    "\n",
    "#### 2.2 Loss error function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install --upgrade --ignore-installed setuptools\n",
    "\n",
    "pip install python-socketio\n",
    "\n",
    "python drive.py model.h5\n",
    "\n",
    "python drive.py model.h5 run1\n",
    "\n",
    "python video.py run1\n",
    "\n",
    "python video.py run1 --fps 48\n",
    "\n",
    "https://developer.nvidia.com/cuda-10.0-download-archive?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal\n",
    "\n",
    "https://www.geforce.cn/drivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(keras.__version__)#2.2.4\n",
    "print(tf.__version__)#2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras强制使用CPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 43, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               844900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 981,819\n",
      "Trainable params: 981,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 150s 790ms/step - loss: 0.0455 - val_loss: 0.0578\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 156s 823ms/step - loss: 0.0417 - val_loss: 0.0646\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 154s 812ms/step - loss: 0.0395 - val_loss: 0.0525\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 154s 809ms/step - loss: 0.0372 - val_loss: 0.0429\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 161s 845ms/step - loss: 0.0356 - val_loss: 0.0497\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from math import ceil \n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Conv2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "samples=[]\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "        \n",
    "        \n",
    "'''\n",
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    for i in range(3):#center,left,right\n",
    "        source_path = line[i]\n",
    "#         filename = source_path.split('/')[-1]\n",
    "        filename = source_path.split('\\\\')[-1]\n",
    "        current_path = './data/IMG/'+filename\n",
    "        if(os.path.exists(current_path)):\n",
    "            image = cv2.imread(current_path)\n",
    "            images.append(image)\n",
    "            measurement = float(line[3])\n",
    "            measurements.append(measurement)\n",
    "'''\n",
    "\n",
    "'''\n",
    "#Data augmentation        \n",
    "augmented_images, augmented_measurements = [],[]\n",
    "for image, measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_measurements.append(measurement*-1.0)\n",
    "\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)\n",
    "'''\n",
    "\n",
    "########################################################################\n",
    "#Model Architecture\n",
    "########################################################################\n",
    "#Use Keras to train a network to do the following:\n",
    "#1.Take in an image from the center camera of the car. This is the input to your neural network.\n",
    "#2.Output a new steering angle for the car. \n",
    "\n",
    "model = Sequential()\n",
    "#Set up lambda layer\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "#Cropping2D Layer\n",
    "# model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), strides=(2, 2), activation=\"relu\"))\n",
    "model.add(Conv2D(36, (5,5), strides=(2,2), activation=\"relu\"))\n",
    "model.add(Conv2D(48, (5,5), strides=(2,2), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#LeNet\n",
    "# model.add(Convolution2D(6, 5, 5, activation=\"relu\"))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Convolution2D(6, 5, 5, activation=\"relu\"))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(120))\n",
    "# model.add(Dense(84))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "########################################################################\n",
    "#Data augmentation        \n",
    "########################################################################\n",
    "def data_augment(images, measurements):\n",
    "    augmented_images, augmented_measurements = [],[]\n",
    "    for image, measurement in zip(images, measurements):\n",
    "        augmented_images.append(image)\n",
    "        augmented_measurements.append(measurement)\n",
    "        augmented_images.append(cv2.flip(image, 1))\n",
    "        augmented_measurements.append(measurement*-1.0)\n",
    "\n",
    "    return augmented_images,augmented_measurements\n",
    "\n",
    "########################################################################\n",
    "#Generator\n",
    "########################################################################\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for row in batch_samples:\n",
    "                '''\n",
    "                for i in range(3):#center,left,right\n",
    "                    source_path = batch_sample[i]\n",
    "            #         filename = source_path.split('/')[-1]\n",
    "                    filename = source_path.split('\\\\')[-1]\n",
    "                    current_path = './data/IMG/'+filename\n",
    "                    if(os.path.exists(current_path)):\n",
    "#                         image = cv2.imread(current_path)\n",
    "#                         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                        image = Image.open(current_path)\n",
    "                        images.append(image)\n",
    "                        measurement = float(line[3])\n",
    "                        angles.append(measurement)\n",
    "                '''\n",
    "                steering_center = float(row[3])\n",
    "\n",
    "                # create adjusted steering measurements for the side camera images\n",
    "                correction = 0.2 # this is a parameter to tune\n",
    "                steering_left = steering_center + correction\n",
    "                steering_right = steering_center - correction\n",
    "\n",
    "                # read in images from center, left and right cameras\n",
    "                path = \"./data/IMG/\" # fill in the path to your training IMG directory\n",
    "                img_center = np.asarray(Image.open(path + row[0].split('\\\\')[-1]))\n",
    "                img_left = np.asarray(Image.open(path + row[1].split('\\\\')[-1]))\n",
    "                img_right = np.asarray(Image.open(path + row[2].split('\\\\')[-1]))\n",
    "\n",
    "                # add images and angles to data set\n",
    "                images.append(img_center)\n",
    "                images.append(img_left)\n",
    "                images.append(img_right)\n",
    "                angles.append(steering_center)\n",
    "                angles.append(steering_left)\n",
    "                angles.append(steering_right)\n",
    "#                 images.extend(img_center, img_left, img_right)\n",
    "#                 angles.extend(steering_center, steering_left, steering_right)\n",
    "\n",
    "            augmented_images, augmented_measurements = data_augment(images, angles)\n",
    "            X_train = np.array(augmented_images)\n",
    "            y_train = np.array(augmented_measurements)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            \n",
    "            \n",
    "########################################################################\n",
    "########################################################################\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.3)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#Compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)          \n",
    "          \n",
    "model.summary()   \n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=5)\n",
    "history_object = model.fit_generator(train_generator, \n",
    "                                     steps_per_epoch=ceil(len(train_samples)/batch_size),\n",
    "                                     validation_data=validation_generator, \n",
    "                                     validation_steps=ceil(len(validation_samples)/batch_size), \n",
    "                                     epochs=5, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "model.save(\"model.h5\")\n",
    "          \n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "#     len(train_samples), validation_data = \n",
    "#     validation_generator,\n",
    "#     nb_val_samples = len(validation_samples), \n",
    "#     nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Data Collection\n",
    "Here are some general guidelines for data collection:\n",
    "\n",
    "* two or three laps of center lane driving\n",
    "* one lap of recovery driving from the sides\n",
    "* one lap focusing on driving smoothly around curves\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
